{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6388384",
   "metadata": {},
   "source": [
    "# Exercise: Deforestation Detection with Foundation Models\n",
    "\n",
    "**Notice: This Notebook is not yet complete. Currently only the Unsupervised Part of the Notebook can reliably be used!**\n",
    "\n",
    "In this exercise, you'll apply foundation model embeddings to detect deforestation in the Amazon rainforest.\n",
    "\n",
    "## Learning Objectives\n",
    "- Load and visualize satellite imagery for a deforestation hotspot\n",
    "- Extract and explore foundation model embeddings\n",
    "- Apply unsupervised clustering to identify land cover patterns\n",
    "- Train a supervised classifier to detect deforestation\n",
    "- Evaluate model performance and interpret results\n",
    "\n",
    "## Background: Why Deforestation Detection?\n",
    "\n",
    "Deforestation in the Amazon has accelerated in recent years, with significant impacts on:\n",
    "- **Climate Change**: The Amazon stores ~150-200 billion tons of carbon\n",
    "- **Biodiversity**: Home to 10% of Earth's species\n",
    "- **Indigenous Communities**: Millions depend on the forest\n",
    "- **Regional Climate**: Affects rainfall patterns across South America\n",
    "\n",
    "Traditional monitoring requires extensive field surveys. Foundation models enable:\n",
    "- **Rapid Detection**: Identify changes quickly from satellite imagery\n",
    "- **Scalable Monitoring**: Cover vast areas efficiently\n",
    "- **Early Warning**: Detect clearing before it becomes widespread\n",
    "\n",
    "## About the Study Area\n",
    "\n",
    "We'll focus on a region at the border of **Pará and Mato Grosso** states in Brazil, which has experienced significant deforestation due to:\n",
    "- Cattle ranching expansion\n",
    "- Soy cultivation\n",
    "- Logging operations\n",
    "- Road construction opening new areas (particularly along BR-163 highway)\n",
    "\n",
    "This area is part of the \"arc of deforestation\" - the agricultural frontier advancing into the Amazon. You'll see a mix of intact forest, recent clearings, and agricultural land.\n",
    "\n",
    "In this notebook, when we talk about deforestation, we refer to any kind of observable canopy loss. Sometimes it might be unclear what exactly the reason for this was (e.g wildfire, human intervention, other...)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf748df1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, install required packages and import helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5b91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "%pip install numpy pandas matplotlib rasterio seaborn xarray pyproj dask rioxarray pystac-client planetary-computer scikit-learn pyarrow tqdm scipy leafmap -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cb2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "def in_colab():\n",
    "    try:\n",
    "        import google.colab\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "if in_colab():\n",
    "    !git clone https://github.com/rohansaw/FoundationModels4EO.git\n",
    "    %cd FoundationModels4EO\n",
    "else:\n",
    "    print(\"Running locally - skipping git clone\")\n",
    "\n",
    "# Import helper functions\n",
    "from geo_helpers import (\n",
    "    load_sentinel2_rgb_timeseries,\n",
    "    load_foundation_model_embeddings,\n",
    "    create_embedding_rgb,\n",
    "    compute_clusters,\n",
    "    predict_on_embeddings\n",
    ")\n",
    "\n",
    "from viz_helpers import (\n",
    "    plot_embeddings_rgb,\n",
    "    plot_clustering_results,\n",
    "    plot_classification_results,\n",
    "    show_study_area_map,\n",
    "    plot_classification_vs_clustering,\n",
    "    plot_rgb_comparison,\n",
    "    plot_rgb_with_change_magnitude,\n",
    "    plot_rgb_with_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553d89ae",
   "metadata": {},
   "source": [
    "## Part 1: Define Study Area and Explore Imagery\n",
    "\n",
    "**TODO #1**: Define the bounding box for your study area in Brazil.\n",
    "\n",
    "We've selected a region at the border of Pará and Mato Grosso states, known for active deforestation. The coordinates are provided below.\n",
    "\n",
    "**Your Task**: \n",
    "- Run the cell to visualize the study area on an interactive map\n",
    "- Examine the region and note:\n",
    "  - Where do you see intact forest?\n",
    "  - Where do you see cleared areas?\n",
    "  - Can you identify roads or agricultural fields?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db26c47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Study area in Pará/Mato Grosso, Brazil - active deforestation zone\n",
    "# Centered around lat: -7.03416, lon: -52.46191\n",
    "LON_MIN, LON_MAX = -52.48, -52.36\n",
    "LAT_MIN, LAT_MAX = -7.06, -6.93\n",
    "# Specify two years between 2018 and 2025: baseline_year and target_year\n",
    "baseline_year = 2019  # baseline (before) year - change as needed (2018-2025)\n",
    "target_year = 2024    # target (after) year - change as needed (2018-2025)\n",
    "\n",
    "# Validate allowed year range (2018-2025)\n",
    "for y in (baseline_year, target_year):\n",
    "    if y < 2018 or y > 2025:\n",
    "        raise ValueError(f\"Year {y} is outside the allowed range 2018-2025\")\n",
    "\n",
    "# Visualize the study area\n",
    "print(\"Study Area: Pará/Mato Grosso, Brazil\")\n",
    "show_study_area_map(LON_MIN, LON_MAX, LAT_MIN, LAT_MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72f8fa",
   "metadata": {},
   "source": [
    "### Load Satellite Imagery - Compare 2019 vs 2024\n",
    "\n",
    "**TODO #2**: Load Sentinel-2 RGB imagery to detect deforestation over time.\n",
    "\n",
    "We'll compare imagery from 2019 (before recent deforestation) and 2024 (current state) to visualize changes.\n",
    "\n",
    "The dry season (May-September) in the Amazon is best for detecting deforestation because:\n",
    "- Less cloud cover\n",
    "- Cleared areas are more visible\n",
    "- Burning activity peaks during this period\n",
    "\n",
    "**Your Task**:\n",
    "- Run the cell to load 2 images from 2019 and 2 from 2024\n",
    "- Compare the before/after imagery\n",
    "- Can you spot deforestation that occurred between 2019 and 2024?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9c07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 RGB imagery - comparing baseline_year vs target_year\n",
    "# We'll load 2 images from each year during the dry season (example: June and August)\n",
    "\n",
    "print(f\"Loading imagery from {baseline_year} and {target_year} for comparison...\")\n",
    "\n",
    "# Baseline imagery (2 images from dry season)\n",
    "rgb_baseline = load_sentinel2_rgb_timeseries(\n",
    "    LON_MIN, LON_MAX, LAT_MIN, LAT_MAX, baseline_year, [8]  # June and August\n",
    ")\n",
    "\n",
    "# Target imagery (2 images from dry season)\n",
    "rgb_target = load_sentinel2_rgb_timeseries(\n",
    "    LON_MIN, LON_MAX, LAT_MIN, LAT_MAX, target_year, [8]  # June and August\n",
    ")\n",
    "\n",
    "print(f\"Baseline image shape: {rgb_baseline[list(rgb_baseline.keys())[0]].shape}\")\n",
    "print(f\"Target image shape: {rgb_target[list(rgb_target.keys())[0]].shape}\")\n",
    "\n",
    "\n",
    "# Visualize side-by-side for easy comparison\n",
    "plot_rgb_comparison(rgb_baseline, rgb_target, \"Pará/Mato Grosso, Brazil\", baseline_year, target_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd6d899",
   "metadata": {},
   "source": [
    "## Part 2: Load and Visualize Foundation Model Embeddings\n",
    "\n",
    "**TODO #3**: Load the Alpha Earth embeddings for your study area.\n",
    "\n",
    "Instead of working directly with raw satellite imagery (which has many spectral bands and temporal dimensions), we'll use pre-computed embeddings from Google's Alpha Earth foundation model.\n",
    "\n",
    "**Your Task**:\n",
    "- Run the cell to load embeddings\n",
    "- Note the shape of the embedding array\n",
    "- Think about: What do these 64 dimensions represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ac506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load foundation model embeddings for the study area for both years\n",
    "# We'll load embeddings for baseline_year and target_year so we can compare features over time\n",
    "# This will take around 3 minutes as we are downloading quite some data\n",
    "embeddings_target = load_foundation_model_embeddings(LON_MIN, LON_MAX, LAT_MIN, LAT_MAX, target_year)\n",
    "\n",
    "embeddings_baseline = load_foundation_model_embeddings(LON_MIN, LON_MAX, LAT_MIN, LAT_MAX, baseline_year)\n",
    "\n",
    "print(f\"Baseline embeddings ({baseline_year}) shape: {embeddings_baseline.shape}\")\n",
    "print(f\"Target embeddings ({target_year}) shape: {embeddings_target.shape}\")\n",
    "print(f\"  - {embeddings_target.shape[0]} feature dimensions\")\n",
    "print(f\"  - {embeddings_target.shape[1]} x {embeddings_target.shape[2]} pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f81c854",
   "metadata": {},
   "source": [
    "### Compute Change Between Years\n",
    "\n",
    "**TODO #3b**: Calculate the embedding difference to detect changes.\n",
    "\n",
    "For deforestation detection, we want to identify **what changed** between the baseline and target years. We compute this by taking the difference between embeddings.\n",
    "\n",
    "**Your Task**:\n",
    "- Run the cell to compute the change embeddings\n",
    "- Examine the magnitude of changes across the region\n",
    "- Identify regions with high change (bright areas)\n",
    "- Compare with the before/after RGB imagery\n",
    "- Do the high-change areas correspond to visible deforestation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64123e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute change embeddings: target - baseline\n",
    "# This captures what changed between the two years\n",
    "embeddings_change = embeddings_target - embeddings_baseline\n",
    "\n",
    "print(f\"Change embeddings shape: {embeddings_change.shape}\")\n",
    "print(f\"\\nChange statistics:\")\n",
    "print(f\"  Mean absolute change: {np.abs(embeddings_change).mean():.4f}\")\n",
    "print(f\"  Max change: {embeddings_change.max():.4f}\")\n",
    "print(f\"  Min change: {embeddings_change.min():.4f}\")\n",
    "print(f\"\\nLarge changes may indicate:\")\n",
    "print(\"  - Deforestation (forest -> cleared land)\")\n",
    "print(\"  - Afforestation (cleared -> vegetation)\")\n",
    "print(\"  - Agricultural conversion\")\n",
    "print(\"  - Natural disturbances (fire, flooding)\")\n",
    "\n",
    "# Compute change magnitude (L2 norm across all 64 dimensions)\n",
    "change_magnitude = np.linalg.norm(embeddings_change, axis=0)\n",
    "print(f\"\\nChange magnitude range: {change_magnitude.min():.4f} to {change_magnitude.max():.4f}\")\n",
    "\n",
    "# Visualize: Baseline RGB, Target RGB, and Change Magnitude side-by-side\n",
    "baseline_month = list(rgb_baseline.keys())[0]\n",
    "target_month = list(rgb_target.keys())[0]\n",
    "\n",
    "plot_rgb_with_change_magnitude(\n",
    "    rgb_baseline[baseline_month], \n",
    "    rgb_target[target_month], \n",
    "    change_magnitude,\n",
    "    baseline_year, \n",
    "    target_year, \n",
    "    baseline_month, \n",
    "    target_month\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f64cc79",
   "metadata": {},
   "source": [
    "## Part 3: Unsupervised Clustering on Change Embeddings\n",
    "\n",
    "**TODO #5**: Apply k-means clustering to identify patterns in the change embeddings.\n",
    "\n",
    "By clustering the **change** embeddings rather than single-year embeddings, we might be able to identify different types of land cover transitions:\n",
    "- Forest -> Cleared (deforestation)\n",
    "- Stable forest (no change)\n",
    "- Stable cleared/agriculture (no change)\n",
    "- Cleared -> Regrowth (afforestation)\n",
    "- Other transitions\n",
    "\n",
    "**Your Task**:\n",
    "- Run clustering with the provided k values\n",
    "- **Experiment**: Try different numbers of clusters (e.g., [3, 7, 15])\n",
    "- Identify which clusters represent:\n",
    "  - High-change areas (likely deforestation)\n",
    "  - Low-change areas (stable land cover)\n",
    "  - Different types of transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a6e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Experiment with different numbers of clusters\n",
    "number_of_clusters_to_explore = [3, 5, 10]  # Try changing this!\n",
    "\n",
    "# Compute clusters on the CHANGE embeddings (what changed between years)\n",
    "print(\"Computing clusters on change embeddings... (this may take a moment)\")\n",
    "cluster_results = compute_clusters(embeddings_change, k_values=number_of_clusters_to_explore)\n",
    "\n",
    "# Visualize each clustering result with RGB images side-by-side\n",
    "baseline_month = list(rgb_baseline.keys())[0]\n",
    "target_month = list(rgb_target.keys())[0]\n",
    "\n",
    "for k in number_of_clusters_to_explore:\n",
    "    plot_rgb_with_clusters(\n",
    "        rgb_baseline[baseline_month],\n",
    "        rgb_target[target_month],\n",
    "        cluster_results[k],\n",
    "        k,\n",
    "        baseline_year,\n",
    "        target_year,\n",
    "        baseline_month,\n",
    "        target_month\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b856e481",
   "metadata": {},
   "source": [
    "**Analysis Questions**:\n",
    "1. What happens when you increase the number of clusters?\n",
    "2. Can you identify a cluster that separates high-change from low-change areas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e228cb",
   "metadata": {},
   "source": [
    "## Advanced Exercise - Voluntary Homework\n",
    "## Part 4: Supervised Classification - Load Labeled Data\n",
    "\n",
    "**TODO #6**: Load reference data with embeddings from both years.\n",
    "\n",
    "Note: This task will likely take a few hours as it requires to get familiar with Google Earth Engine and the dataset.\n",
    "\n",
    "For supervised deforestation detection, you first require some reference data. This is the main challenge of this exercise: Curating a deforestation training-testing dataset. There are datasets on Google Earth Engine that hold data on deforestation, such as [Hansen Global Forest Change](https://developers.google.com/earth-engine/datasets/catalog/UMD_hansen_global_forest_change_2024_v1_12#bands). You will have to identify how to work with this dataset and extract a number of samples from different classes to a CSV. Choose a baseline and a target year that you are interested in (e.g 2019 and 2025 as above)\n",
    "\n",
    "**CSV Structure:**\n",
    "- Coordinates: `latitude`, `longitude`\n",
    "- Land cover class: `class_name` (forest, deforested, non-forest), `label` (0, 1, 2)\n",
    "- Baseline year embeddings: 64 columns named `A0_baseline`, `A1_baseline`, ..., `A63_baseline`\n",
    "- Target year embeddings: 64 columns named `A0_target`, `A1_target`, ..., `A63_target`\n",
    "\n",
    "This gives you 128 embedding columns (64 for each year) plus metadata for the same sample points.\n",
    "\n",
    "You can build your export code based on the `export_alphaearth_embeddings_GEE.py` script\n",
    "\n",
    "**Your Task**:\n",
    "- Get familiar with GEE\n",
    "- Build a reference dataset (e.g., from [Hansen Global Forest Change](https://developers.google.com/earth-engine/datasets/catalog/UMD_hansen_global_forest_change_2024_v1_12#bands))\n",
    "- Randomly sample 1000 points from class that should be: forest (stable), deforested (changed in your timerange), non-forest (stable)\n",
    "- Export embeddings for both baseline_year and target_year for each point\n",
    "- Structure columns as: coordinates, labels, A0_baseline...A63_baseline, A0_target...A63_target\n",
    "- Download CSV to `demo_data/` folder\n",
    "- Run the cell below to load and examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766dda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-extracted embeddings with labels from BOTH years in a single CSV\n",
    "# The CSV contains AlphaEarth embeddings for the same labeled points across both years\n",
    "\n",
    "# Update this filename to match your exported CSV\n",
    "samples_csv = f\"demo_data/deforestation_samples_{baseline_year}_{target_year}.csv\"\n",
    "\n",
    "print(f\"Loading samples with embeddings from both {baseline_year} and {target_year}...\")\n",
    "print(f\"File: {samples_csv}\")\n",
    "\n",
    "samples_df = pd.read_csv(samples_csv)\n",
    "\n",
    "print(f\"\\nLoaded {len(samples_df)} samples\")\n",
    "print(f\"\\nColumns in CSV: {list(samples_df.columns[:10])}... (showing first 10)\")\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(samples_df['class_name'].value_counts())\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(samples_df[['longitude', 'latitude', 'class_name', 'label']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0dab8",
   "metadata": {},
   "source": [
    "### Compute Change Embeddings from CSV\n",
    "\n",
    "**TODO #6b**: Compute change embeddings from the baseline and target columns.\n",
    "\n",
    "Since the CSV contains embeddings from both years (suffixed with `_baseline` and `_target`), we can directly compute the change by subtracting:\n",
    "- `change_embedding = target_embedding - baseline_embedding`\n",
    "\n",
    "This creates 64-dimensional change vectors for each sample.\n",
    "\n",
    "**Your Task**:\n",
    "- Run the cell to extract baseline and target embeddings\n",
    "- Compute change embeddings by subtraction\n",
    "- Verify the data structure is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64702450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute change embeddings by subtracting baseline from target\n",
    "# Extract embedding columns (suffixed with _baseline and _target)\n",
    "\n",
    "# Get baseline embedding columns (A0_baseline, A1_baseline, ..., A63_baseline)\n",
    "baseline_cols = [col for col in samples_df.columns if col.endswith('_baseline')]\n",
    "baseline_cols.sort()  # Ensure correct order: A0, A1, ..., A63\n",
    "\n",
    "# Get target embedding columns (A0_target, A1_target, ..., A63_target)\n",
    "target_cols = [col for col in samples_df.columns if col.endswith('_target')]\n",
    "target_cols.sort()  # Ensure correct order: A0, A1, ..., A63\n",
    "\n",
    "print(f\"Found {len(baseline_cols)} baseline embedding dimensions\")\n",
    "print(f\"Found {len(target_cols)} target embedding dimensions\")\n",
    "\n",
    "if len(baseline_cols) != 64 or len(target_cols) != 64:\n",
    "    raise ValueError(f\"Expected 64 embedding dimensions for each year, got {len(baseline_cols)} and {len(target_cols)}\")\n",
    "\n",
    "# Extract embeddings as numpy arrays\n",
    "embeddings_baseline_csv = samples_df[baseline_cols].values\n",
    "embeddings_target_csv = samples_df[target_cols].values\n",
    "\n",
    "print(f\"\\nBaseline embeddings shape: {embeddings_baseline_csv.shape}\")\n",
    "print(f\"Target embeddings shape: {embeddings_target_csv.shape}\")\n",
    "\n",
    "# Compute change embeddings: target - baseline\n",
    "change_features = embeddings_target_csv - embeddings_baseline_csv\n",
    "\n",
    "print(f\"\\nChange feature shape: {change_features.shape}\")\n",
    "print(f\"  - {change_features.shape[0]} samples\")\n",
    "print(f\"  - {change_features.shape[1]} dimensions (64-d change vectors)\")\n",
    "print(f\"\\nChange statistics:\")\n",
    "print(f\"  Mean absolute change: {np.abs(change_features).mean():.4f}\")\n",
    "print(f\"  Max change: {change_features.max():.4f}\")\n",
    "print(f\"  Min change: {change_features.min():.4f}\")\n",
    "\n",
    "# Add change features to dataframe for later use\n",
    "samples_df['change_features'] = list(change_features)\n",
    "\n",
    "print(f\"\\n Data ready for training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17781876",
   "metadata": {},
   "source": [
    "### Prepare Training and Test Splits Using Change Features\n",
    "\n",
    "**TODO #7**: Create balanced train and test sets from the change embeddings.\n",
    "\n",
    "We'll use the change embeddings (target - baseline) as features. This focuses the model on **what changed** rather than the state at a single time point.\n",
    "\n",
    "**Your Task**:\n",
    "- Adjust the number of training and test samples per class\n",
    "- Run the cell to create the splits\n",
    "- Note: We're training on **change vectors**, not single-year embeddings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1da99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training and test splits from CHANGE embeddings\n",
    "# TODO: Experiment with different numbers of training samples\n",
    "\n",
    "NUM_SAMPLES = {\n",
    "    'forest': {'label': 0, 'n_train': 20, 'n_test': 100},\n",
    "    'deforested': {'label': 1, 'n_train': 20, 'n_test': 100},\n",
    "    'non-forest': {'label': 2, 'n_train': 20, 'n_test': 100}\n",
    "}\n",
    "\n",
    "# Prepare train/test split on change features\n",
    "np.random.seed(42)\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "for class_name, class_config in NUM_SAMPLES.items():\n",
    "    class_label = class_config['label']\n",
    "    n_train = class_config['n_train']\n",
    "    n_test = class_config['n_test']\n",
    "    \n",
    "    # Get all indices for this class\n",
    "    class_indices = np.where(samples_df['label'] == class_label)[0]\n",
    "    \n",
    "    if len(class_indices) < n_train + n_test:\n",
    "        print(f\"Warning: Class {class_name} has only {len(class_indices)} samples\")\n",
    "        n_train = min(n_train, len(class_indices) // 2)\n",
    "        n_test = len(class_indices) - n_train\n",
    "    \n",
    "    # Sample training and test indices\n",
    "    train_idx = np.random.choice(class_indices, n_train, replace=False)\n",
    "    remaining = list(set(class_indices) - set(train_idx))\n",
    "    test_idx = np.random.choice(remaining, min(n_test, len(remaining)), replace=False)\n",
    "    \n",
    "    train_indices.extend(train_idx)\n",
    "    test_indices.extend(test_idx)\n",
    "\n",
    "train_indices = np.array(train_indices)\n",
    "test_indices = np.array(test_indices)\n",
    "np.random.shuffle(train_indices)\n",
    "np.random.shuffle(test_indices)\n",
    "\n",
    "# Prepare X and y using change features\n",
    "X_train = change_features[train_indices]\n",
    "y_train = samples_df.iloc[train_indices]['label'].values\n",
    "X_test = change_features[test_indices]\n",
    "y_test = samples_df.iloc[test_indices]['label'].values\n",
    "\n",
    "print(f\"Training set: {len(X_train)} samples\")\n",
    "print(f\"Test set: {len(X_test)} samples\")\n",
    "print(f\"Feature dimension: {X_train.shape[1]} (change embeddings)\")\n",
    "print(f\"\\nClass distribution in training:\")\n",
    "for class_name, class_config in NUM_SAMPLES.items():\n",
    "    count = np.sum(y_train == class_config['label'])\n",
    "    print(f\"  {class_name}: {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103e69f2",
   "metadata": {},
   "source": [
    "### Visualize Sample Locations\n",
    "\n",
    "**TODO #8**: Examine the spatial distribution of training and test samples.\n",
    "\n",
    "Understanding where your samples come from is critical for:\n",
    "- Detecting spatial bias\n",
    "- Understanding spatial autocorrelation\n",
    "- Ensuring representative coverage\n",
    "\n",
    "**Your Task**:\n",
    "- Run the cells to create interactive maps\n",
    "- Examine the spatial distribution\n",
    "- Are train and test samples well-separated geographically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bd256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sample coordinates for visualization\n",
    "from viz_helpers import plot_sample_map_by_class, plot_sample_map_by_split\n",
    "\n",
    "# Add split column for visualization\n",
    "samples_df['split'] = 'unused'\n",
    "samples_df.iloc[train_indices, samples_df.columns.get_loc('split')] = 'train'\n",
    "samples_df.iloc[test_indices, samples_df.columns.get_loc('split')] = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec7bd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all samples by land cover class\n",
    "m_all = plot_sample_map_by_class(samples_df, center_lat=-7.03, center_lon=-52.46, zoom=9)\n",
    "m_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fb79b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train vs test split\n",
    "m_split = plot_sample_map_by_split(samples_df, center_lat=-7.03, center_lon=-52.46, zoom=9)\n",
    "m_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee53d8b2",
   "metadata": {},
   "source": [
    "### Train the Classifier on Change Embeddings\n",
    "\n",
    "**TODO #9**: Train a Random Forest classifier on change features.\n",
    "\n",
    "The model will learn to classify change patterns:\n",
    "- **Forest** (class 0): Areas that remained forested\n",
    "- **Deforested** (class 1): Areas where forest was cleared between baseline and target years\n",
    "- **Non-forest** (class 2): Areas that were already non-forest in both years\n",
    "\n",
    "**Your Task**:\n",
    "- Run the training cell\n",
    "- The model learns from **change vectors**, not static land cover\n",
    "- Note how few training samples we need with foundation models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0246970e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train a Random Forest classifier on CHANGE embeddings\n",
    "print(\"Training Random Forest classifier on change features...\")\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Training complete!\")\n",
    "print(f\"\\nModel trained on {len(X_train)} samples (change embeddings)\")\n",
    "print(f\"Test Accuracy: {accuracy:.2%}\")\n",
    "\n",
    "# Show detailed results\n",
    "class_names = ['forest', 'deforested', 'non-forest']\n",
    "plot_classification_results(y_test, y_pred, accuracy, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af612b1e",
   "metadata": {},
   "source": [
    "**Analysis Questions**:\n",
    "1. How does the model perform on detecting deforestation (class 1)?\n",
    "2. Which transitions are most confused with each other?\n",
    "   - Is stable forest sometimes confused with deforestation?\n",
    "   - Is stable non-forest mistaken for deforestation?\n",
    "3. What might cause classification errors in change detection?\n",
    "   - Seasonal vegetation changes vs. actual clearing?\n",
    "   - Cloud shadows or atmospheric effects?\n",
    "4. How would you improve the change detection model?\n",
    "   - More training samples?\n",
    "   - Additional temporal snapshots?\n",
    "   - Multi-temporal features?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2e763f",
   "metadata": {},
   "source": [
    "## Part 5: Apply Classifier to Full Study Area\n",
    "\n",
    "**TODO #10**: Use the trained classifier to predict change patterns for every pixel.\n",
    "\n",
    "Now we'll apply the model to classify the entire study area based on **change embeddings** into:\n",
    "- Forest (green): Areas that remained forested\n",
    "- Deforested (red): Areas where forest was cleared\n",
    "- Non-forest (yellow): Areas that were already non-forest\n",
    "\n",
    "**Your Task**:\n",
    "- Run the prediction cell\n",
    "- Examine the output map\n",
    "- Compare with the RGB imagery, change magnitude map, and clustering results\n",
    "- Do the deforested areas match visible clearing in the imagery?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0562a0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Apply classifier to all pixels using CHANGE embeddings\n",
    "print(f\"Predicting deforestation for entire study area using change ({baseline_year} -> {target_year})...\")\n",
    "# Use CHANGE embeddings for spatial prediction (what changed between years)\n",
    "predictions = predict_on_embeddings(clf, embeddings_change)\n",
    "\n",
    "print(f\"Prediction complete!\")\n",
    "print(f\"\\nChange detection results:\")\n",
    "class_names = ['Stable Forest', 'Deforested', 'Stable Non-forest']\n",
    "for label, name in enumerate(class_names):\n",
    "    count = np.sum(predictions == label)\n",
    "    pct = 100 * count / predictions.size\n",
    "    print(f\"  {name}: {pct:.1f}%\")\n",
    "\n",
    "print(f\"\\nDeforestation summary: {np.sum(predictions == 1)} pixels ({100*np.sum(predictions == 1)/predictions.size:.1f}%)\")\n",
    "print(f\"classified as deforested between {baseline_year} and {target_year}\")\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.imshow(predictions, cmap='RdYlGn', vmin=0, vmax=2)\n",
    "plt.colorbar(label='Change Class', ticks=[0, 1, 2], \n",
    "             format=plt.FuncFormatter(lambda x, p: class_names[int(x)] if int(x) < len(class_names) else ''))\n",
    "plt.title(f'Deforestation Detection: {baseline_year} -> {target_year}\\n(Green=Stable Forest, Red=Deforested, Yellow=Stable Non-forest)', \n",
    "          fontsize=14, fontweight='bold')\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d17b6",
   "metadata": {},
   "source": [
    "### Compare Supervised vs Unsupervised Results on Change\n",
    "\n",
    "**TODO #11**: Compare supervised classification with clustering on change embeddings.\n",
    "\n",
    "Both methods analyze the **change** between years, but:\n",
    "- **Clustering**: Unsupervised, finds natural groupings in change patterns\n",
    "- **Classification**: Supervised, learns from labeled examples\n",
    "\n",
    "**Your Task**:\n",
    "- Run the comparison visualization\n",
    "- Analyze the differences:\n",
    "  - Where do they agree on deforestation?\n",
    "  - Where do they disagree?\n",
    "  - Which approach better identifies clearing events?\n",
    "  - Does supervised learning provide clearer deforestation boundaries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5fffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare classification with clustering (both on change embeddings)\n",
    "print(\"Comparing supervised classification with unsupervised clustering...\")\n",
    "print(\"Both methods analyze CHANGE between years, not single-year land cover\")\n",
    "\n",
    "plot_classification_vs_clustering(\n",
    "    embeddings_change,\n",
    "    None,\n",
    "    predictions,\n",
    "    {5: cluster_results[5]},  # Use k=5 clustering\n",
    "    class_names=['Stable Forest', 'Deforested', 'Stable Non-forest']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1281fd7",
   "metadata": {},
   "source": [
    "## Part 6: Analysis and Interpretation\n",
    "\n",
    "**TODO #12**: Analyze your results and reflect on the exercise.\n",
    "\n",
    "**Discussion Questions**:\n",
    "\n",
    "1. **Change Detection Approach**:\n",
    "   - What types of changes does the model capture beyond deforestation?\n",
    "   - How does the change magnitude relate to deforestation severity?\n",
    "   - Could you detect regrowth/afforestation with this approach?\n",
    "\n",
    "2. **Model Performance**:\n",
    "   - How well does your classifier identify deforested areas from change patterns?\n",
    "   - What types of errors do you observe (false positives/negatives)?\n",
    "   - Are there areas with high change magnitude but low deforestation probability?\n",
    "   - What might explain stable areas with subtle changes?\n",
    "\n",
    "3. **Training Data**:\n",
    "   - How many samples did you use for each change class?\n",
    "   - Why do we need labels for both stable and changed areas?\n",
    "   - How would multi-year training data (e.g., 2018->2020, 2020->2022) improve the model?\n",
    "   - What is spatial autocorrelation and why does it matter for change detection?\n",
    "\n",
    "4. **Supervised vs Unsupervised on Change**:\n",
    "   - How do clustering results on change embeddings differ from classification?\n",
    "   - Can clustering identify unexpected change types?\n",
    "   - Which method better separates deforestation from natural variation?\n",
    "   - Could you use clustering to identify training samples?\n",
    "\n",
    "5. **Real-World Application**:\n",
    "   - How could this approach enable near-real-time deforestation alerts?\n",
    "   - What cadence (weekly, monthly, annual) would be most useful?\n",
    "   - What additional validation would you need before operational deployment? Think also about generalizing in time.\n",
    "   - How would you distinguish intentional clearing from natural disturbances (fire, storms)?\n",
    "\n",
    "6. **Foundation Models for Change Detection**:\n",
    "   - How do pre-trained embeddings capture temporal changes?\n",
    "   - What would change if you worked with raw spectral indices (NDVI, etc.)?\n",
    "   - Could the model detect subtle degradation before complete clearing?\n",
    "   - How would you adapt this to other change detection tasks (urbanization, flooding)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970478b2",
   "metadata": {},
   "source": [
    "### Important Lessons:\n",
    "\n",
    "1. **Change detection via embedding subtraction** - by subtracting embeddings we can capture change\n",
    "2. **Foundation models capture temporal dynamics** enabling effective change detection with few samples\n",
    "3. **Change magnitude maps** provide unsupervised change screening before classification\n",
    "4. **Multi-temporal embeddings** (baseline + target) are essential for deforestation detection\n",
    "\n",
    "### Resources:\n",
    "\n",
    "- [Global Forest Watch](https://www.globalforestwatch.org/): Real-time deforestation monitoring\n",
    "- [Google Earth Engine](https://earthengine.google.com/): Petabyte-scale geospatial analysis\n",
    "- [Alpha Earth Model](https://arxiv.org/pdf/2507.22291): Foundation model documentation\n",
    "- [Sentinel-2 Documentation](https://sentinels.copernicus.eu/web/sentinel/missions/sentinel-2): Satellite mission details\n",
    "- [MapBiomas](https://mapbiomas.org/): Annual land cover maps for Brazil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e536fb7e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-project)",
   "language": "python",
   "name": "other-project-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
